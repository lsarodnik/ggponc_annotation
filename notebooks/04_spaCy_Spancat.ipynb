{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd282e9-2b3b-4319-9eb0-d60b9fd968f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prediction of overlapping spans with spaCy's SpanCategorizer\n",
    "\n",
    "**Motivation**:\n",
    "\n",
    "Annotations in GGPONC are often overlapping or nested.\n",
    "\n",
    "For instance, `Versagen einer Behandlung mit Oxaliplatin und Irinotecan`\n",
    "- is a *Finding*\n",
    "- which contains a *Therapeutic Procedure*: `Behandlung mit Oxaliplatin und Irinotecan`:\n",
    "    - which in turn contains two *Clinical Drug* names: (`Oxaliplatin` and `Irinotecan`).\n",
    "\n",
    "Standard IOB-encoded labels, and most NER implementations, can only model one label per token, so by default we consider the longest surrounding mention span only in the IOB-based / HuggingFace implementation (in this case, the *Finding*).\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "Instead of token-level labels, we use spaCy's new [SpanCategorizer](https://spacy.io/api/spancategorizer/) implementation to predict overlapping mention spans as a SpanGroup in a spaCy document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add8d33-0eaa-47f7-856d-630e54581a7b",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "See the `spacy` folder in the root directory of the project. The model configuration can be found at `configs` and training can be run through a spaCy project (see `spacy/run_training.sh`). \n",
    "\n",
    "*Note:* We have currently not optimized the many hyperparameters related to span suggestion and model training. However, performance is close to the HuggingFace models evaluated on non-nested mention spans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cd5b1-300e-4710-a85f-e2413bb33df7",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357713b1-2285-4923-826b-f7e58178c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14a1448-ab8c-4cf7-9fd8-c728b21514f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, Span\n",
    "import snomed_spans #TODO: import needed to enable custom spaCy components, is there another way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23f22a8-c73d-4508-a756-f220d167e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'de_pipeline' (0.0.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/models/spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "844d6044-d4f1-4d1d-b608-a0069d03617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Versagen einer Behandlung mit Oxaliplatin und Irinotecan\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e211c2b5",
   "metadata": {},
   "source": [
    "### Grascco Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20601a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"6.04.2029: Nachdebridement am Kopf, VAG-Wechsel linke Hand\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f493809",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"6.04.2029: Nachdebridement am Kopf, VAG-Wechsel linke Hand\"\"Röntgen : Rippstein I : Gute Hüftkopfepiphysenkonturgebung , minimale Lateralisation , li. etwas stärker als re. , noch übergreifende Pfannendächer , Shenton-Menard-Linie nicht wesentlich unterbrochen , Pfannendachwinkel Ii. 30° , re. ebenfalls knapp 30° .\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f547e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading .spacy file ...\n",
      "working ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y100sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y100sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread_text(encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y100sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m docs \u001b[39m=\u001b[39m nlp(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "from spacy.training import docs_to_json\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Corpus\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.vocab import Vocab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_raw = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/source\"\n",
    "manual_annotated_file = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grassco_anno_2023-01-05_0021/spacy/test.spacy\"\n",
    "p = Path(r'/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/source').glob('*.txt')\n",
    "files = [x for x in p if x.is_file()]\n",
    "\n",
    "\n",
    "\n",
    "print(\"loading .spacy file ...\")\n",
    "#gold_annotation = nlp.from_disk(manual_annotated_file)\n",
    "#doc_bin = DocBin().from_disk(manual_annotated_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"working ...\")\n",
    "text = \"\"\n",
    "#text = \"\"\n",
    "for file in files:\n",
    "    text += file.read_text(encoding=\"utf-8\")\n",
    "docs = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5dcaf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files merged...\n",
      "NLP Pipe...\n",
      "Department Orthopädie und Traumatologie Friedrichstraße 55 , 10117 Berlin \n",
      "Building Examples...\n",
      "eval...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "score() missing 1 required positional argument: 'examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y101sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m scores \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39mscore(examples)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y101sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m#example_object = iter(docs)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y101sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y101sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y101sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m#examples = Example(Doc.from_docs(docs), Doc.from_docs(gold_docs))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y101sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m scorer\u001b[39m.\u001b[39;49mscore()\n",
      "\u001b[0;31mTypeError\u001b[0m: score() missing 1 required positional argument: 'examples'"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_bin = DocBin().from_disk(manual_annotated_file)\n",
    "\n",
    "\n",
    "gold_docs  = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "#scorer = Scorer()\n",
    "#scores = scorer.score(examples)\n",
    "\n",
    "#gold_annotation = spacy.Corpus.v1(manual_annotated_file, gold_preproc=True)\n",
    "docs = []\n",
    "for file in files:\n",
    "    docs.append(file.read_text(encoding=\"utf-8\"))\n",
    "print(\"Files merged...\")\n",
    "\n",
    "\n",
    "# Loop over the gold standard data\n",
    "#for gold_doc in gold_docs:\n",
    "#    ents1 = [(gold_doc.text, gold_doc.label_) for ent in gold_doc.ents]\n",
    "    # Process the text with the model\n",
    "# Compare the model's predicted annotations with the gold standard\n",
    "#for doc in docs:\n",
    "#    ents2 = [(doc.text, doc.label_) for ent in doc.ents]\n",
    "\n",
    "print(\"NLP Pipe...\")\n",
    "docs_all = nlp.pipe(gold_docs, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"],batch_size = 10)\n",
    "\n",
    "\n",
    "print(gold_docs[1])\n",
    "print(\"Building Examples...\")\n",
    "examples = []\n",
    "for  i, doc in enumerate(docs_all):\n",
    "    examples.append(Example((doc), gold_docs[i]))\n",
    "    \n",
    "\n",
    "\n",
    "scorer = Scorer(nlp)\n",
    "\n",
    "print(\"eval...\")\n",
    "scores = scorer.score(examples)\n",
    "\n",
    "\n",
    "#example_object = iter(docs)\n",
    "\n",
    "\n",
    "#examples = Example(Doc.from_docs(docs), Doc.from_docs(gold_docs))\n",
    "\n",
    "scorer.score()\n",
    "\n",
    "\n",
    "#print(\"Entities F-Score:\", scorer.scores[\"ents_f\"])\n",
    "#print(\"Entities Precision:\", scorer.scores[\"ents_p\"])\n",
    "#print(\"Entities Recall:\", scorer.scores[\"ents_r\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f72f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Scorer' object has no attribute 'scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scorer \u001b[39m=\u001b[39m Scorer()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scores \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39mscore(examples)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y102sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEntities F-Score:\u001b[39m\u001b[39m\"\u001b[39m, scorer\u001b[39m.\u001b[39;49mscores[\u001b[39m\"\u001b[39m\u001b[39ments_f\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y102sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEntities Precision:\u001b[39m\u001b[39m\"\u001b[39m, scorer\u001b[39m.\u001b[39mscores[\u001b[39m\"\u001b[39m\u001b[39ments_p\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y102sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEntities Recall:\u001b[39m\u001b[39m\"\u001b[39m, scorer\u001b[39m.\u001b[39mscores[\u001b[39m\"\u001b[39m\u001b[39ments_r\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Scorer' object has no attribute 'scores'"
     ]
    }
   ],
   "source": [
    "scorer = Scorer()\n",
    "\n",
    "scores = scorer.score(examples)\n",
    "\n",
    "print(\"Entities F-Score:\", scorer.scores[\"ents_f\"])\n",
    "print(\"Entities Precision:\", scorer.scores[\"ents_p\"])\n",
    "print(\"Entities Recall:\", scorer.scores[\"ents_r\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a007a0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sentence[\u001b[39m'\u001b[39m\u001b[39moffsets\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "sentence['offsets']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc426969",
   "metadata": {},
   "source": [
    "## Initial Sentence Based Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a60a0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'de_pipeline' (0.0.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current document_id: Albers.tsv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "nlp = spacy.load('../data/models/spacy')\n",
    "\n",
    "def find_annotated_entities(sentence, document):\n",
    "    s_offsets = sentence['offsets']\n",
    "    entity_list = []\n",
    "    for entity in document['entities']:\n",
    "        if entity is None:\n",
    "            break\n",
    "        elif(entity['offsets'][0][0] > s_offsets[0][1]): \n",
    "            break\n",
    "        elif (entity['offsets'][0][0] >=  s_offsets[0][0] and entity['offsets'][0][1] <= s_offsets[0][1]):\n",
    "            entity_list.append(entity)\n",
    "    return entity_list\n",
    "\n",
    "tp = 0\n",
    "e_count = 0\n",
    "t_count = 0\n",
    "\n",
    "def compare_findings(predi_entities, truth_entities, sentence):\n",
    "    sentence_delta = sentence['offsets'][0][0]\n",
    "    global tp, e_count, t_count\n",
    "    for e in list(predi_entities.spans['snomed']):\n",
    "        e_count+=1\n",
    "        for t in truth_entities:\n",
    "            if e.label_ == t['type'] and e.start_char == t['offsets'][0][0]-sentence_delta and e.end_char == t['offsets'][0][1]-sentence_delta:\n",
    "                tp+=1\n",
    "                break\n",
    "    t_count += len(truth_entities)\n",
    "\n",
    "\n",
    "json_path = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grassco_anno_2023-01-05_0021/json/fine/long/test.json\"\n",
    "json_path_new = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grascco_hpi_anno_2023_02_08/annotations/json/fine/long/all_short.json\"\n",
    "\n",
    "with open(json_path_new) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "for document in data:\n",
    "    print(\"Current document_id: \"+document['document_id'])\n",
    "    for sentence in document['passages']:\n",
    "        nlp_findings = nlp(sentence['text'], disable=[\"tok2vec\", \"tagger\", \"attribute_ruler\",\"lemmatizer\"]) #disable_components (standard NER tagger etc.) - \"parser\" is helpful (10 matches less when not used)\n",
    "        manual_findings = find_annotated_entities(sentence, document)\n",
    "        compare_findings(nlp_findings, manual_findings, sentence)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df884b6d",
   "metadata": {},
   "source": [
    "## Sentence Based Processing (Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88770942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current document_id: Weil.tsv\n",
      "Current document_id: Recklinghausen.tsv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y122sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m document \u001b[39min\u001b[39;00m data:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y122sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCurrent document_id: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdocument[\u001b[39m'\u001b[39m\u001b[39mdocument_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y122sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, nlp_findings \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(nlp\u001b[39m.\u001b[39mpipe([d[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m document[\u001b[39m'\u001b[39m\u001b[39mpassages\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m d]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y122sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m , disable\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtok2vec\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtagger\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mattribute_ruler\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mlemmatizer\u001b[39m\u001b[39m\"\u001b[39m])): \u001b[39m# use pipe, disable_components in pipe (standard NER tagger etc.) - \"parser\" is helpful (10 matches less when not used)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y122sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         manual_findings \u001b[39m=\u001b[39m find_annotated_entities(document[\u001b[39m'\u001b[39m\u001b[39mpassages\u001b[39m\u001b[39m'\u001b[39m][i], document)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/notebooks/04_spaCy_Spancat.ipynb#Y122sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         tp_i, e_count_i, t_count_i \u001b[39m=\u001b[39m compare_findings(nlp_findings, manual_findings, document[\u001b[39m'\u001b[39m\u001b[39mpassages\u001b[39m\u001b[39m'\u001b[39m][i])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/spacy/language.py:1589\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[1;32m   1588\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1589\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[1;32m   1590\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/spacy/util.py:1651\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1644\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1645\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1648\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1649\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1650\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1651\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1652\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/spacy/pipeline/spancat.py:278\u001b[0m, in \u001b[0;36mSpanCategorizer.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc2f(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict((docs, indices))  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mreturn\u001b[39;00m indices, scores\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    312\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times), forward at line 55 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/thinc/layers/maxout.py:53\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[0;32m---> 53\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(X, W, trans2\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     54\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[1;32m     55\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def find_annotated_entities(sentence, document):\n",
    "    s_offsets = sentence['offsets']\n",
    "    return [entity for entity in document['entities']\n",
    "            if entity and\n",
    "            (entity['offsets'][0][0] >= s_offsets[0][0] and\n",
    "            entity['offsets'][0][1] <= s_offsets[0][1])]\n",
    "            \n",
    "def compare_findings(predi_entities, truth_entities, sentence):\n",
    "    sentence_delta = sentence['offsets'][0][0]\n",
    "    tp = sum(1 for e in predi_entities.spans['snomed'] if any(e.label_ == t['type'] and e.start_char == t['offsets'][0][0] - sentence_delta and e.end_char == t['offsets'][0][1] - sentence_delta for t in truth_entities))\n",
    "    return tp, len(predi_entities.spans['snomed']), len(truth_entities)\n",
    "\n",
    "tp = e_count = t_count = 0\n",
    "\n",
    "json_path = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grassco_anno_2023-01-05_0021/json/fine/long/test.json\"\n",
    "json_path_new = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grascco_hpi_anno_2023_02_08/annotations/json/fine/long/all_short.json\"\n",
    "\n",
    "with open(json_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "for document in data:\n",
    "    print(\"Current document_id: \"+document['document_id'])\n",
    "    for i, nlp_findings in enumerate(nlp.pipe([d['text'] for d in document['passages'] if 'text' in d]\n",
    ", disable=[\"tok2vec\", \"tagger\", \"attribute_ruler\",\"lemmatizer\"])): # use pipe, disable_components in pipe (standard NER tagger etc.) - \"parser\" is helpful (10 matches less when not used)\n",
    "        manual_findings = find_annotated_entities(document['passages'][i], document)\n",
    "        tp_i, e_count_i, t_count_i = compare_findings(nlp_findings, manual_findings, document['passages'][i])\n",
    "        tp += tp_i\n",
    "        e_count += e_count_i\n",
    "        t_count += t_count_i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "473c097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Entities: 6234\n",
      "Predicted Entities: 5101\n",
      "True Positives: 2381\n",
      "False Positives: 2720\n",
      "False Negatives: 3853\n",
      "Precision: 0.47\n",
      "Recall: 0.38\n",
      "F1 Score: 0.42\n",
      "tp: 2381 e_count: 5101 t_count: 6234\n",
      "precision: 0.46677122132915116 recall: 0.38193776066730833 f1_score: 0.42011468901632115\n"
     ]
    }
   ],
   "source": [
    "fn = t_count-tp\n",
    "fp = e_count-tp\n",
    "\n",
    "print(f'Actual Entities: {t_count}')\n",
    "print(f'Predicted Entities: {e_count}')\n",
    "\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1_score:.2f}')\n",
    "\n",
    "\n",
    "#result for fine/long\n",
    "\n",
    "#Actual Entities: 6194\n",
    "#Predicted Entities: 5171\n",
    "#True Positives: 2584\n",
    "#False Positives: 2587\n",
    "#False Negatives: 3610\n",
    "#Precision: 0.50\n",
    "#Recall: 0.42\n",
    "#F1 Score: 0.45\n",
    "\n",
    "#result for fine/short\n",
    "#Actual Entities: 7201\n",
    "#Predicted Entities: 5171\n",
    "#True Positives: 1737\n",
    "#False Positives: 3434\n",
    "#False Negatives: 5464\n",
    "#Precision: 0.34\n",
    "#Recall: 0.24\n",
    "#F1 Score: 0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df2f582c-bcf0-466c-99bb-6a06328cbb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versagen einer Behandlung Diagnosis_or_Pathology\n",
      "Behandlung mit Oxaliplatin und Irinotecan Therapeutic\n",
      "Oxaliplatin Clinical_Drug\n",
      "Irinotecan Clinical_Drug\n"
     ]
    }
   ],
   "source": [
    "for s in sorted(list(doc.spans['snomed']), key=lambda s: s.start):\n",
    "    print(s, s.label_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9478a3e2",
   "metadata": {},
   "source": [
    "## Document Based Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all documents... this takes up to multiple minutes hang tight!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#nlp = spacy.load('../data/models/spacy')\n",
    "\n",
    "def get_string_sentences(docs):\n",
    "    return ['\\n'.join([sentence['text'] for sentence in doc['passages']]) for doc in docs]\n",
    "\n",
    "def find_annotated_entities(annotated_doc):\n",
    "    return [entity for entity in annotated_doc['entities'] if entity]\n",
    "\n",
    "def compare_findings(predicted_findings, truth_entities):\n",
    "    predicted_findings = sorted(predicted_findings, key=lambda x: x.start_char)\n",
    "    truth_set = set(t['offsets'][0][0] for t in truth_entities)\n",
    "    tp, e_count, t_count = 0, len(predicted_findings), len(truth_entities)\n",
    "    for e in predicted_findings:\n",
    "        if e.start_char in truth_set:\n",
    "            t = next(t for t in truth_entities if t['offsets'][0][0] == e.start_char)\n",
    "            if e.label_ == t['type'] and e.start_char == t['offsets'][0][0] and e.end_char == t['offsets'][0][1]:\n",
    "                tp += 1\n",
    "    return tp, e_count, t_count\n",
    "\n",
    "tp, e_count, t_count = 0, 0, 0\n",
    "\n",
    "json_path = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grassco_anno_2023-01-05_0021/json/fine/long/test.json\"\n",
    "json_path_new = \"/Users/leon.sarodnik/Documents/GitHub/ggponc_annotation/GraSSco/grascco_hpi_anno_2023_02_08/annotations/json/fine/long/all_short.json\"\n",
    "\n",
    "with open(json_path_new) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "print(\"Processing all documents... this takes up to multiple minutes hang tight!\")\n",
    "\n",
    "# use pipe, disable_components in pipe (standard NER tagger etc.) - \"parser\" is helpful (10 matches less when not used)\n",
    "for i, doc in enumerate(nlp.pipe(get_string_sentences(data), disable=[\"tok2vec\", \"attribute_ruler\", \"lemmatizer\"])):\n",
    "    predicted_findings = [(ent) for ent in list(doc.spans['snomed'])]\n",
    "    manual_findings = find_annotated_entities(data[i])\n",
    "    tp_i, e_count_i, t_count_i = compare_findings(predicted_findings, manual_findings)\n",
    "    tp += tp_i\n",
    "    e_count += e_count_i\n",
    "    t_count += t_count_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a36fd872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Entities: 195\n",
      "Predicted Entities: 177\n",
      "True Positives: 81\n",
      "False Positives: 96\n",
      "False Negatives: 114\n",
      "Precision: 0.46\n",
      "Recall: 0.42\n",
      "F1 Score: 0.44\n"
     ]
    }
   ],
   "source": [
    "fn = t_count-tp\n",
    "fp = e_count-tp\n",
    "\n",
    "print(f'Actual Entities: {t_count}')\n",
    "print(f'Predicted Entities: {e_count}')\n",
    "\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1_score:.2f}')\n",
    "\n",
    "\n",
    "#sentence based result for all-short\n",
    "\n",
    "#Actual Entities: 195\n",
    "#Predicted Entities: 187\n",
    "#True Positives: 87\n",
    "#False Positives: 100\n",
    "#False Negatives: 108\n",
    "#Precision: 0.47\n",
    "#Recall: 0.45\n",
    "#F1 Score: 0.46\n",
    "\n",
    "#document based result for all-short\n",
    "\n",
    "#Actual Entities: 195\n",
    "#Predicted Entities: 177\n",
    "#True Positives: 81\n",
    "#False Positives: 96\n",
    "#False Negatives: 114\n",
    "#Precision: 0.46\n",
    "#Recall: 0.42\n",
    "#F1 Score: 0.44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
